import os
import google.generativeai as genai
from openai import OpenAI

# Gemini APIã‚­ãƒ¼ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
genai.configure(api_key="AIzaSyDKlxe4hT8O7e8Je_lfZk5EjbI53ZI367Q") 

# OpenAI APIã‚­ãƒ¼ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆç›´æ¥è¨­å®šï¼‰
client = OpenAI(api_key="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") 

def get_gemini_response(prompt_text):
    """
    Gemini APIã‚’å‘¼ã³å‡ºã—ã¦å¿œç­”ã‚’å–å¾—ã™ã‚‹é–¢æ•°
    """
    try:
        model = genai.GenerativeModel('gemini-1.5-flash')
        response = model.generate_content(prompt_text)
        return response.text
    except Exception as e:
        return f"Gemini APIå‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

def get_chatgpt_response(prompt_text):
    """
    ChatGPT APIã‚’å‘¼ã³å‡ºã—ã¦å¿œç­”ã‚’å–å¾—ã™ã‚‹é–¢æ•°
    """
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "user", "content": prompt_text}
            ],
            max_tokens=500,
            temperature=0.7
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"ChatGPT APIå‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

def compare_ai_responses(query):
    """
    Geminiã¨ChatGPTã®ä¸¡æ–¹ã«è³ªå•ã—ã¦å›ç­”ã‚’æ¯”è¼ƒã™ã‚‹é–¢æ•°
    """
    print(f"è³ªå•: {query}")
    print("=" * 50)
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
    prompt = f"è³ªå•: {query}ã«ã¤ã„ã¦è©³ã—ãæ•™ãˆã¦ãã ã•ã„ã€‚"
    
    # Geminiã«è³ªå•
    print("ğŸ¤– Geminiã®å›ç­”:")
    print("-" * 30)
    gemini_response = get_gemini_response(prompt)
    print(gemini_response)
    print()
    
    # ChatGPTã«è³ªå•
    print("ğŸ¤– ChatGPTã®å›ç­”:")
    print("-" * 30)
    chatgpt_response = get_chatgpt_response(prompt)
    print(chatgpt_response)
    print()
    
    print("=" * 50)
    print("å›ç­”æ¯”è¼ƒå®Œäº†")

if __name__ == "__main__":
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®å…¥åŠ›ã‚’å—ã‘ä»˜ã‘ã‚‹
    user_query = input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹: ãƒ•ãƒ©ãƒ³ã‚¹ã®æ­´å²ã€æ—¥æœ¬ã®æ–‡åŒ–ï¼‰: ")
    compare_ai_responses(user_query)
